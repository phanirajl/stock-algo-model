{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StockPredictionUpdated.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_KUa8Gy5SA6o","colab_type":"code","outputId":"2704dc23-7881-4bd0-faaf-1faafaa49315","executionInfo":{"status":"ok","timestamp":1544906093019,"user_tz":300,"elapsed":1313211,"user":{"displayName":"Seyone Chithrananda","photoUrl":"https://lh6.googleusercontent.com/--YEkcs7G4_w/AAAAAAAAAAI/AAAAAAAAAGk/5-27tI2N5mI/s64/photo.jpg","userId":"16842911736031838650"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["import pandas as pd\n","from google.colab import files\n","uploaded = files.upload()\n","\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-d39e0108-158e-4636-ac82-acae21b50271\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-d39e0108-158e-4636-ac82-acae21b50271\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving data_stocks.csv to data_stocks.csv\n"],"name":"stdout"}]},{"metadata":{"id":"ALIq6rUwleTj","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wVNpFFdalkgm","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ibnxl_dpViLr","colab_type":"code","outputId":"055ff5ee-3f09-4061-8322-5c909ec01d4e","executionInfo":{"status":"ok","timestamp":1544284705065,"user_tz":300,"elapsed":4392,"user":{"displayName":"Seyone Chithrananda","photoUrl":"https://lh6.googleusercontent.com/--YEkcs7G4_w/AAAAAAAAAAI/AAAAAAAAAGk/5-27tI2N5mI/s64/photo.jpg","userId":"16842911736031838650"}},"colab":{"base_uri":"https://localhost:8080/","height":4338}},"cell_type":"code","source":["df = pd.read_csv('data_stocks.csv')\n","print (df)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["             DATE      SP500  NASDAQ.AAL  NASDAQ.AAPL  NASDAQ.ADBE  \\\n","0      1491226200  2363.6101     42.3300     143.6800     129.6300   \n","1      1491226260  2364.1001     42.3600     143.7000     130.3200   \n","2      1491226320  2362.6799     42.3100     143.6901     130.2250   \n","3      1491226380  2364.3101     42.3700     143.6400     130.0729   \n","4      1491226440  2364.8501     42.5378     143.6600     129.8800   \n","5      1491226500  2365.6201     42.5399     143.7800     130.0700   \n","6      1491226560  2365.2000     42.4700     143.8640     130.1800   \n","7      1491226620  2365.2900     42.4700     143.8100     130.1400   \n","8      1491226680  2364.3201     42.3900     143.8150     130.1000   \n","9      1491226740  2364.6399     42.3300     143.8000     130.2100   \n","10     1491226800  2364.5801     42.4000     143.8900     130.1400   \n","11     1491226860  2364.4800     42.2900     143.9700     130.3700   \n","12     1491226920  2365.2300     42.2900     143.9199     130.4599   \n","13     1491226980  2365.6599     42.3900     144.0239     130.6300   \n","14     1491227040  2365.2400     42.4197     144.0500     130.6500   \n","15     1491227100  2365.3201     42.4300     144.0638     130.6950   \n","16     1491227160  2364.9600     42.4400     144.0200     130.5700   \n","17     1491227220  2364.3999     42.4000     144.0200     130.4750   \n","18     1491227280  2364.7400     42.3900     143.9700     130.3700   \n","19     1491227340  2363.9399     42.4400     144.0300     130.3800   \n","20     1491227400  2363.8799     42.3800     143.9800     130.2900   \n","21     1491227460  2363.6001     42.3400     143.9000     130.3500   \n","22     1491227520  2364.0400     42.2950     143.9100     130.4400   \n","23     1491227580  2363.8301     42.2800     143.9100     130.4700   \n","24     1491227640  2363.8501     42.2500     143.8600     130.4700   \n","25     1491227700  2363.0300     42.2600     143.8600     130.2800   \n","26     1491227760  2363.2500     42.2100     143.8935     130.2600   \n","27     1491227820  2362.8701     42.2000     143.9300     130.2200   \n","28     1491227880  2363.0300     42.1700     143.9500     130.1700   \n","29     1491227940  2363.0601     42.1400     143.8700     130.1800   \n","...           ...        ...         ...          ...          ...   \n","41236  1504207860  2473.1001     44.7200     164.0700     155.0800   \n","41237  1504207920  2473.7600     44.7150     164.0750     155.0700   \n","41238  1504207980  2473.8201     44.7850     164.1500     155.1200   \n","41239  1504208040  2473.8899     44.8000     164.1300     155.1300   \n","41240  1504208100  2474.0701     44.7800     164.1400     155.1300   \n","41241  1504208160  2474.1499     44.7800     164.1450     155.1100   \n","41242  1504208220  2474.5000     44.7900     164.2050     155.1000   \n","41243  1504208280  2474.6101     44.7800     164.2350     155.1300   \n","41244  1504208340  2474.5100     44.8000     164.2900     155.1600   \n","41245  1504208400  2474.4900     44.7850     164.2800     155.1600   \n","41246  1504208460  2474.7800     44.7800     164.2600     155.1200   \n","41247  1504208520  2474.8201     44.7800     164.2634     155.1100   \n","41248  1504208580  2474.8999     44.8000     164.2400     155.0800   \n","41249  1504208640  2474.5200     44.8300     164.2700     155.1300   \n","41250  1504208700  2473.3201     44.8300     164.2000     155.1100   \n","41251  1504208760  2473.3201     44.7550     164.1350     155.0900   \n","41252  1504208820  2473.6101     44.7300     164.1800     155.0600   \n","41253  1504208880  2473.1001     44.7150     164.2300     155.0700   \n","41254  1504208940  2473.3501     44.7450     164.2100     155.0700   \n","41255  1504209000  2472.5100     44.7400     164.1850     155.0600   \n","41256  1504209060  2471.8899     44.7200     164.1600     155.0600   \n","41257  1504209120  2472.7700     44.7300     164.0600     155.0100   \n","41258  1504209180  2472.8999     44.7600     164.1900     155.1200   \n","41259  1504209240  2472.6399     44.7500     164.2000     155.0900   \n","41260  1504209300  2472.0200     44.7100     164.1400     155.0400   \n","41261  1504209360  2472.2200     44.7200     164.1100     155.0900   \n","41262  1504209420  2471.7700     44.7300     164.1200     155.1600   \n","41263  1504209480  2470.0300     44.7400     164.0100     155.0650   \n","41264  1504209540  2471.4900     44.7100     163.8800     154.9600   \n","41265  1504209600  2471.4900     44.7400     163.9800     155.1600   \n","\n","       NASDAQ.ADI  NASDAQ.ADP  NASDAQ.ADSK  NASDAQ.AKAM  NASDAQ.ALXN  \\\n","0         82.0400    102.2300      85.2200      59.7600     121.5200   \n","1         82.0800    102.1400      85.6500      59.8400     121.4800   \n","2         82.0300    102.2125      85.5100      59.7950     121.9300   \n","3         82.0000    102.1400      85.4872      59.6200     121.4400   \n","4         82.0350    102.0600      85.7001      59.6200     121.6000   \n","5         82.0400    102.0400      85.9200      59.6100     121.7000   \n","6         82.1200    102.3300      85.9120      59.5400     121.6300   \n","7         82.1900    102.3700      85.8200      59.4100     121.6100   \n","8         82.2300    102.3800      85.8800      59.4300     121.7150   \n","9         82.1650    102.3300      85.8600      59.2600     121.8500   \n","10        82.2100    102.2000      85.8900      59.2700     122.1000   \n","11        82.1500    102.2800      85.9600      59.3600     122.1650   \n","12        82.1450    102.2700      85.9500      59.1650     122.1300   \n","13        82.1600    102.3100      86.0500      59.2000     121.9700   \n","14        82.2100    102.3200      86.1300      59.1450     122.0100   \n","15        82.1500    102.2800      86.1250      59.2000     122.0450   \n","16        82.1400    102.3000      86.3000      59.0901     121.9800   \n","17        82.1143    102.2100      86.3800      59.1800     122.0000   \n","18        82.0400    102.1700      86.5064      59.1600     122.0000   \n","19        82.1500    102.1800      86.6000      59.0399     121.9850   \n","20        82.0800    102.1500      86.6500      59.1350     121.9000   \n","21        82.0800    102.1900      86.6900      59.0750     121.7500   \n","22        82.0100    102.2200      86.8700      59.0400     121.7900   \n","23        81.9800    102.2100      87.0800      59.0500     121.7000   \n","24        82.0100    102.2100      86.8240      58.9800     121.7100   \n","25        81.9500    102.1700      86.6881      58.9599     121.7400   \n","26        81.8700    102.1900      86.6100      58.8950     121.4900   \n","27        81.8500    102.2000      86.4900      58.8000     121.5500   \n","28        81.7700    102.2500      86.4500      58.8000     121.5400   \n","29        81.8400    102.2400      86.3876      58.6801     121.5500   \n","...           ...         ...          ...          ...          ...   \n","41236     83.8000    106.4600     114.4300      47.2000     142.6500   \n","41237     83.8000    106.4600     114.4200      47.1900     142.6200   \n","41238     83.8050    106.5000     114.4900      47.2200     142.6000   \n","41239     83.6900    106.4900     114.5000      47.2100     142.6100   \n","41240     83.6600    106.5100     114.5100      47.2500     142.5800   \n","41241     83.7900    106.5400     114.5100      47.2500     142.6200   \n","41242     83.7500    106.6000     114.5300      47.2650     142.5600   \n","41243     83.7100    106.6300     114.5790      47.2600     142.6200   \n","41244     83.7100    106.6550     114.5500      47.2500     142.4900   \n","41245     83.6500    106.6500     114.5833      47.2500     142.5600   \n","41246     83.7200    106.6600     114.5700      47.2400     142.5400   \n","41247     83.7600    106.6900     114.5900      47.2300     142.5824   \n","41248     83.7850    106.7050     114.6300      47.2400     142.5600   \n","41249     83.8200    106.7800     114.6600      47.2400     142.5800   \n","41250     83.8100    106.7400     114.6400      47.2300     142.7300   \n","41251     83.7300    106.6600     114.5600      47.2100     142.6900   \n","41252     83.7300    106.6200     114.5000      47.2100     142.5700   \n","41253     83.7299    106.6500     114.4900      47.2100     142.5800   \n","41254     83.7100    106.6500     114.5100      47.2000     142.5800   \n","41255     83.7100    106.6500     114.4700      47.1500     142.5300   \n","41256     83.7100    106.6200     114.5300      47.1350     142.6450   \n","41257     83.7000    106.5600     114.5100      47.1150     142.4600   \n","41258     83.6300    106.6200     114.5600      47.1250     142.8750   \n","41259     83.6900    106.6000     114.5150      47.1300     142.8300   \n","41260     83.6600    106.6300     114.4500      47.1450     142.6300   \n","41261     83.6700    106.5650     114.4900      47.1500     142.4250   \n","41262     83.6500    106.5900     114.5200      47.1500     142.4500   \n","41263     83.6200    106.5200     114.4700      47.1500     142.3300   \n","41264     83.5800    106.4000     114.3300      47.1350     142.1700   \n","41265     83.6900    106.4700     114.4600      47.1500     142.4100   \n","\n","         ...     NYSE.WYN  NYSE.XEC  NYSE.XEL  NYSE.XL  NYSE.XOM  NYSE.XRX  \\\n","0        ...      84.3700  119.0350    44.400  39.8800   82.0300    7.3600   \n","1        ...      84.3700  119.0350    44.110  39.8800   82.0300    7.3800   \n","2        ...      84.5850  119.2600    44.090  39.9800   82.0200    7.3600   \n","3        ...      84.4600  119.2600    44.250  39.9900   82.0200    7.3500   \n","4        ...      84.4700  119.6100    44.110  39.9600   82.0300    7.3600   \n","5        ...      84.4825  119.5800    44.150  39.9600   82.0300    7.3600   \n","6        ...      84.5000  119.3200    44.200  39.9800   82.0566    7.3650   \n","7        ...      84.5200  119.1100    44.120  39.9500   82.0000    7.3600   \n","8        ...      84.4800  119.3100    44.120  39.9300   81.9500    7.3700   \n","9        ...      84.4000  119.1500    44.170  39.8600   81.9000    7.3650   \n","10       ...      84.4400  119.0900    44.140  39.8800   81.8000    7.3700   \n","11       ...      84.4300  119.0300    44.140  39.8700   81.8000    7.3620   \n","12       ...      84.4200  118.9300    44.170  39.8800   81.7700    7.3700   \n","13       ...      84.3600  119.0100    44.170  39.9300   81.7850    7.3608   \n","14       ...      84.3500  119.0000    44.160  39.9200   81.8400    7.3700   \n","15       ...      84.3000  118.7350    44.160  39.9100   81.7800    7.3500   \n","16       ...      84.3300  118.8700    44.100  39.9400   81.7889    7.3500   \n","17       ...      84.2600  119.2800    44.120  39.9400   81.8500    7.3450   \n","18       ...      84.2500  119.1300    44.120  39.9300   81.8300    7.3250   \n","19       ...      84.2600  119.3000    44.130  39.9393   81.8462    7.3200   \n","20       ...      84.2600  119.2300    44.130  39.8900   81.8000    7.3050   \n","21       ...      84.2500  119.3900    44.150  39.8600   81.8400    7.3000   \n","22       ...      84.2950  119.3800    44.180  39.8600   81.9190    7.3000   \n","23       ...      84.2100  119.3300    44.180  39.8900   81.8650    7.3000   \n","24       ...      84.2900  119.1540    44.190  39.8800   81.8299    7.3150   \n","25       ...      84.3402  119.1100    44.180  39.8900   81.7950    7.3100   \n","26       ...      84.3600  119.1200    44.240  39.9100   81.8250    7.3000   \n","27       ...      84.3300  119.1100    44.230  39.8900   81.7930    7.3000   \n","28       ...      84.3300  118.8650    44.230  39.8800   81.8000    7.3050   \n","29       ...      84.3300  119.1200    44.220  39.8900   81.8500    7.3100   \n","...      ...          ...       ...       ...      ...       ...       ...   \n","41236    ...      99.5850   99.8500    49.530  41.0100   76.4250   32.2900   \n","41237    ...      99.5700   99.9000    49.530  41.0000   76.4650   32.2900   \n","41238    ...      99.5900   99.8900    49.535  41.0050   76.4650   32.2900   \n","41239    ...      99.6100   99.8600    49.540  41.0000   76.4600   32.2867   \n","41240    ...      99.6050   99.8400    49.495  40.9900   76.4250   32.2900   \n","41241    ...      99.5600   99.8301    49.515  40.9850   76.4300   32.2900   \n","41242    ...      99.5850   99.7600    49.515  40.9800   76.4400   32.2950   \n","41243    ...      99.6050   99.7500    49.515  40.9800   76.4150   32.3000   \n","41244    ...      99.6000   99.7600    49.530  40.9600   76.4050   32.3000   \n","41245    ...      99.6200   99.7200    49.535  40.9600   76.3900   32.3000   \n","41246    ...      99.6250   99.7025    49.540  40.9950   76.4050   32.3000   \n","41247    ...      99.6350   99.7300    49.535  41.0050   76.4050   32.2950   \n","41248    ...      99.6600   99.7200    49.535  41.0150   76.4263   32.2700   \n","41249    ...      99.6700   99.6400    49.495  41.0100   76.4100   32.2700   \n","41250    ...      99.6775   99.5350    49.490  40.9900   76.3900   32.2700   \n","41251    ...      99.6800   99.5950    49.480  40.9950   76.3834   32.2750   \n","41252    ...      99.6900   99.5800    49.485  40.9900   76.4150   32.3000   \n","41253    ...      99.6700   99.6200    49.490  41.0000   76.4150   32.3100   \n","41254    ...      99.6600   99.6150    49.485  40.9950   76.3900   32.3050   \n","41255    ...      99.6850   99.5850    49.485  41.0000   76.4050   32.2950   \n","41256    ...      99.6900   99.4950    49.480  40.9900   76.3900   32.2900   \n","41257    ...      99.6800   99.4700    49.470  40.9750   76.3650   32.2950   \n","41258    ...      99.6850   99.4900    49.480  40.9700   76.3750   32.3000   \n","41259    ...      99.6800   99.5000    49.475  40.9700   76.3750   32.2950   \n","41260    ...      99.6600   99.4900    49.495  40.9750   76.4000   32.2950   \n","41261    ...      99.6750   99.5300    49.485  40.9550   76.3600   32.2850   \n","41262    ...      99.7300   99.6300    49.480  40.9600   76.3700   32.2950   \n","41263    ...      99.7350   99.6400    49.495  40.9400   76.3150   32.2900   \n","41264    ...      99.7000   99.6300    49.485  40.9250   76.3000   32.2750   \n","41265    ...      99.6700   99.6400    49.490  40.9400   76.3200   32.2700   \n","\n","       NYSE.XYL  NYSE.YUM  NYSE.ZBH  NYSE.ZTS  \n","0       50.2200   63.8600  122.0000   53.3500  \n","1       50.2200   63.7400  121.7700   53.3500  \n","2       50.1200   63.7500  121.7000   53.3650  \n","3       50.1600   63.8800  121.7000   53.3800  \n","4       50.2000   63.9100  121.6950   53.2400  \n","5       50.2000   63.8400  121.8500   53.2200  \n","6       50.3300   63.8300  122.1000   53.3300  \n","7       50.3000   63.8300  122.2800   53.3700  \n","8       50.2500   63.8500  121.8750   53.3300  \n","9       50.2200   63.8400  121.9300   53.4000  \n","10      50.2450   63.8600  121.8600   53.3800  \n","11      50.2300   63.8800  121.8050   53.3900  \n","12      50.1900   63.8600  121.9400   53.4000  \n","13      50.2400   63.9100  122.0100   53.4250  \n","14      50.2200   63.9400  122.0000   53.4100  \n","15      50.1900   63.9900  122.0100   53.3600  \n","16      50.1850   63.9200  122.0500   53.4000  \n","17      50.1900   63.9000  121.9972   53.4000  \n","18      50.1800   63.8800  121.9600   53.4100  \n","19      50.1600   63.8600  122.0500   53.3900  \n","20      50.1550   63.8750  122.0100   53.3400  \n","21      50.1707   63.9100  122.0200   53.3300  \n","22      50.1700   63.9200  121.9500   53.3000  \n","23      50.1200   63.9800  122.0200   53.3000  \n","24      50.1800   63.9500  122.1500   53.3000  \n","25      50.2000   63.8800  122.1100   53.3150  \n","26      50.1600   63.8600  121.9600   53.3000  \n","27      50.1500   63.8400  121.9500   53.2900  \n","28      50.1400   63.7900  121.7600   53.2900  \n","29      50.1400   63.8000  121.8500   53.2900  \n","...         ...       ...       ...       ...  \n","41236   62.0000   76.6700  114.5600   62.6900  \n","41237   62.0110   76.6800  114.5700   62.6900  \n","41238   62.0200   76.6950  114.5800   62.7000  \n","41239   62.0300   76.6950  114.5800   62.7000  \n","41240   62.0264   76.7100  114.6200   62.7100  \n","41241   62.0200   76.7200  114.6100   62.7050  \n","41242   62.0400   76.7100  114.6001   62.7000  \n","41243   62.0700   76.7200  114.6200   62.7050  \n","41244   62.1100   76.7300  114.6300   62.7050  \n","41245   62.1050   76.7350  114.6500   62.7050  \n","41246   62.1100   76.7200  114.6600   62.7300  \n","41247   62.0950   76.7100  114.6700   62.7350  \n","41248   62.1000   76.7150  114.6600   62.7400  \n","41249   62.1000   76.7400  114.6300   62.7350  \n","41250   62.1300   76.7550  114.5700   62.7500  \n","41251   62.1050   76.7659  114.4100   62.7500  \n","41252   62.0950   76.7700  114.4160   62.7600  \n","41253   62.0900   76.8250  114.4000   62.7650  \n","41254   62.0750   76.7950  114.3800   62.7200  \n","41255   62.1200   76.8000  114.3900   62.7200  \n","41256   62.0600   76.8150  114.3600   62.7300  \n","41257   62.1000   76.8100  114.3100   62.7225  \n","41258   62.1050   76.8799  114.3500   62.7400  \n","41259   62.1050   76.9100  114.3200   62.7400  \n","41260   62.0950   76.8850  114.3000   62.7300  \n","41261   62.1100   76.8800  114.3100   62.7250  \n","41262   62.1000   76.9000  114.3300   62.7100  \n","41263   62.0900   76.8800  114.3100   62.6850  \n","41264   62.0750   76.8300  114.2300   62.6301  \n","41265   62.0700   76.8100  114.2800   62.6800  \n","\n","[41266 rows x 502 columns]\n"],"name":"stdout"}]},{"metadata":{"id":"BdOGGmWxV2u1","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","df = df.drop(['DATE'], 1)\n","\n","# dimensions of dataset\n","n = df.shape[0]\n","p = df.shape[1]\n","\n","df = df.values\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wH7iosqIkWxj","colab_type":"code","colab":{}},"cell_type":"code","source":["# preparing training (80%), test data (20%) - April - August 2017 S&P 500 stock price data\n","\n","#time series prediction data\n","\n","train_start = 0 \n","train_end = int(np.floor(0.8*n))\n","test_start = train_end\n","test_end = n\n","df_train = df[np.arange(train_start, train_end), :]\n","df_test = df[np.arange(test_start, test_end), :]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3IKKQ-JImStF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Scaling the inputs, targets, to allow for activation functions on networks neurons which are bounded to work \n","\n","scaler = MinMaxScaler()\n","df_train = scaler.fit_transform(df_train)\n","df_test = scaler.fit_transform(df_test)\n","\n","# build x and y, do not scale whole data set yet, as in real life time \n","# series prediction we don't have future observations at the time of \n","# forecasting\n","\n","x_train = df_train[:, 1:]\n","y_train = df_train[: 0]\n","x_test = df_test[:, 1:]\n","y_test = df_test [:, 0]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SbCzC4l7nzs9","colab_type":"code","colab":{}},"cell_type":"code","source":["n_stocks = x_train.shape[1]\n","X = tf.placeholder(dtype=tf.float32, shape = [None, n_stocks])\n","Y = tf.placeholder(dtype=tf.float32, shape = [None])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vq8zoNzWE8tW","colab_type":"code","outputId":"87ac1a8a-cad8-4a86-c490-7872c97ab120","executionInfo":{"status":"ok","timestamp":1544284719978,"user_tz":300,"elapsed":395,"user":{"displayName":"Seyone Chithrananda","photoUrl":"https://lh6.googleusercontent.com/--YEkcs7G4_w/AAAAAAAAAAI/AAAAAAAAAGk/5-27tI2N5mI/s64/photo.jpg","userId":"16842911736031838650"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["n_stocks = 500 \n","n_neurons_1 = 1024 # 1st layer, 2nd layer, always half of the previous layer \n","n_neurons_2 = 512\n","n_neurons_3 = 256\n","n_neurons_4 = 128\n","\n","# Session variable\n","net = tf.InteractiveSession()\n","\n","# Initiailizers used in adjusting weights and bioases\n","\n","sigma = 1 # scale\n","weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale = sigma)\n","bias_initializer = tf.zeros_initializer()\n","\n","# weights and biases, second dimension of previous layer = first dimesion of current layer\n","\n","# layer 1 : weights and biases initialized\n","\n","weights_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1])) # input to first layer\n","bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n","\n","# layer 2 : weights and biases initialized\n","weights_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n","bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n","\n","# layer 3 : weights and biases initialized\n","weights_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n","bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n","\n","# layer 4 : weights and biases initialized\n","weights_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n","bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"],"name":"stderr"}]},{"metadata":{"id":"egji6yjzJya4","colab_type":"code","colab":{}},"cell_type":"code","source":["# let's initialize some output weights! \n","weight_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n","bias_out = tf.Variable(bias_initializer([1]))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xu4p8nW2KCGO","colab_type":"code","colab":{}},"cell_type":"code","source":["# specified network architecture - combining data and weights and biases for matrix multiplication\n","# use ReLU activation function for model \n","\n","# feedforward network - data flows from left to right (input layer, hidden layers, output layers)\n","# hidden layers \n","hidden_layer1 = tf.nn.relu(tf.add(tf.matmul(X, weights_hidden_1), bias_hidden_1)) \n","dropped = tf.nn.dropout(hidden_layer1, keep_prob = 0.5)\n","hidden_layer2 = tf.nn.relu(tf.add(tf.matmul(hidden_layer1, weights_hidden_2), bias_hidden_2))\n","dropped = tf.nn.dropout(hidden_layer2, keep_prob = 0.5)\n","hidden_layer3 = tf.nn.relu(tf.add(tf.matmul(hidden_layer2, weights_hidden_3), bias_hidden_3))\n","dropped = tf.nn.dropout(hidden_layer3, keep_prob = 0.5)\n","hidden_layer4 = tf.nn.relu(tf.add(tf.matmul(hidden_layer3, weights_hidden_4), bias_hidden_4))\n","dropped = tf.nn.dropout(hidden_layer4, keep_prob = 1)\n","\n","# output layers\n","\n","out = tf.transpose(tf.add(tf.matmul(hidden_layer4, weight_out), bias_out))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"29OxLkckMRmm","colab_type":"code","colab":{}},"cell_type":"code","source":["# cost function uses mean squared error to compare deviations between model predictions and observed training \n","mse = tf.reduce_mean(tf.squared_difference(out, Y))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_XtgJUXtOf3e","colab_type":"code","colab":{}},"cell_type":"code","source":["#Optimizer - adapts weights and bias variables during training, calculate gradients which indicate \n","# direction of change in weights and biases during training to reduce mse\n","\n","# use AdamOptimizer \n","optimizer = tf.train.AdamOptimizer().minimize(mse)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4F_C2qPxPErV","colab_type":"code","outputId":"c0d2bb18-d9bf-4c69-a783-4a38348a2208","executionInfo":{"status":"error","timestamp":1544904771588,"user_tz":300,"elapsed":1312,"user":{"displayName":"Seyone Chithrananda","photoUrl":"https://lh6.googleusercontent.com/--YEkcs7G4_w/AAAAAAAAAAI/AAAAAAAAAGk/5-27tI2N5mI/s64/photo.jpg","userId":"16842911736031838650"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"cell_type":"code","source":["# Fitting network - training network to draw data samples, make predictions, and use placeholders X and Y \n","# inputs and targets. After prediction, the model optimizes its weights and biases using mse and the Adam\n","# optimizer to update parameters for improved accuracy in predictions. \n","\n","\n","net = tf.Session()\n","net.run(tf.global_variables_initializer())\n","\n","# set up graph to visualize predictions and accuracy\n","plt.ion()\n","fig = plt.figure()\n","ax1 = fig.add_subplot(111)\n","line1, = ax1.plot(y_test)\n","line2, = ax1.plot(y_test*0.5)\n","\n","# epochs represents number of times ran, batch size represents size of data samples fed into training network\n","epochs = 10\n","batch_size = 256\n","mse_train = []\n","mse_test = []\n","\n","for e in range(epochs):\n","    #randomize training data\n","    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n","    x_train = x_train[shuffle_indices] # data randomly selected for training \n","    y_train = y_train[shuffle_indices]\n","    \n","    # training batch data\n","    for i in range (0, len(y_train) // batch_size):\n","      start = i * batch_size\n","      batch_x = x_train[start:start + batch_size]\n","      batch_y = y_train[start:start + batch_size]\n","    \n","    # run optimizer on batch data\n","      net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n","      \n","      # graph progress over epochs\n","      \n","      if np.mod(i, 5) == 0:\n","        \n","          # Prediction \n","          pred = net.run(out, feed_dict={X, X_test})\n","          line2.set_ydata(pred)\n","          plt.title('Epoch #' + str(e) + ', Batch ' + str(i))\n","          file_name = 'img/epoch_' + str(e) + '_batch_' + str(i) + '.jpg'\n","          plt.savefig(file_name)\n","          plt.pause(0.01)\n","          files.download(\"modelimages.png\")\n","\n","# Print final MSE after Training\n","mse_final = net.run(mse, feed_dict={X: x_test, Y: y_test})\n","print(mse_final)\n","\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9d7c2977d8eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]}]}